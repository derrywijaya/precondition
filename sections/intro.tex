\section{Introduction}

In recent years there has been a lot of research on extracting relational facts between entities and storing them in knowledge bases (KBs). These knowledge bases such as YAGO (which extract facts from Wikipedia infoboxes \cite{suchanek2007yago}) or NELL (which extracts facts from any Web text \cite{carlson2010toward,fader2011identifying}) are generally static. They are not updated as the Web changes when in reality new facts arise while others cease to be valid or change over time. One approach towards real-time population of KBs is to extract facts between entities from dynamic content of the web such as news, blogs and user comments in social media \cite{nakashole2012real}. This paper proposes a \textit{shift} of focus from doing KB updates by extracting facts in text to doing them by identifying state changes brought about by addition or deletion of state-changing verbs in text. 

The benefit of such shift is multi-fold. (1) Even when relation between entities is not stated explicitly in text, detecting state change that happens to an entity in text can be used to infer and update the corresponding relational fact in KB and to temporally scope the fact in KB \cite{wijayactp}. (2) Learning state changes brought about by verbs can pave ways to learning the pre- and post-conditions of state-changing verbs: the entry condition (in terms of KB facts) that must be true of the verb's entities for a state-changing event expressed by the verb to take place, and the exit condition (in terms of KB facts) that will be true of the entities after the event occurs. Such pre- and post-conditions can be useful for learning event sequences such as scripts \cite{schank2013scripts}, that can be modeled as a collection of verbs chained together by the pre- and post-condition overlap of their shared entities, for inferring how the effect of one event can be cascaded down to other entities via the pre- and post-condition of the shared entities, or for inferring unknown states of entities from the verbs they participate in.  

In this paper we propose to learn state changes brought about by verbs from the Wikipedia edit histories of entities. Our assumption is that when a state-changing event happens to an entity e.g., marriage, the Wikipedia infobox that contains the underlying KB facts of the entity is updated e.g., by the addition of a new \textsc{spouse} value. At the same time, texts containing verbs expressing the event e.g., \textit{wed} may be added or deleted from the entity's Wiki page. Wikipedia edits of verbs and infobox over many entities that undergo a similar event can act as weakly supervised data for learning verbs and infobox changes that relate to the event. However, Wikipedia infobox edits are notoriously \textit{noisy}: there is no guarantee that only the infobox slots that relate to the particular event will be updated. For example, when an event such as death happens to an entity, infobox slots regarding the entity's birth e.g., \textit{birthdate}, \textit{birthplace}, may also be updated. To alleviate the effect of such noise, we also leverage constraints between infobox slots e.g., that \textit{deathdate} is mutually exclusive with \textit{birthdate} or that \textit{birthdate} is related to \textit{birthplace}, to effectively learn infobox changes that relate to a particular event-expressing verb. From our experiments, we observe that when verbs expressing a state changing event are being added/deleted to an entity's Wikipedia text, we can update the infobox facts about the entity effectively, with an 89\% precision and 74\% recall. 